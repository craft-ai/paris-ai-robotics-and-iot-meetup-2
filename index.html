<!doctype html>
<html lang="en">

  <head>
    <meta charset="utf-8">

    <title>craft ai @ Paris AI, Robotics & IoT Meetup #2</title>

    <meta name="author" content="Clodéric Mars">

    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

    <link rel="stylesheet" href="css/reveal.css">
    <link rel="stylesheet" href="css/theme/craft-ai.css" id="theme">

    <!-- Code syntax highlighting -->
    <link rel="stylesheet" href="lib/css/zenburn.css">

    <!-- Printing and PDF exports -->
    <script>
      var link = document.createElement( 'link' );
      link.rel = 'stylesheet';
      link.type = 'text/css';
      link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
      document.getElementsByTagName( 'head' )[0].appendChild( link );
    </script>

    <!--[if lt IE 9]>
    <script src="lib/js/html5shiv.js"></script>
    <![endif]-->
  </head>

  <body>

    <div class="reveal">

      <!-- Any section element inside of this container is displayed as a slide -->
      <div class="slides">
        <section>
          <section>
            <h1>Paris AI, Robotics & IoT Meetup #2</h1>
            <h3>Clodéric Mars</h3>
            <img class="logo" src='http://www.craft.ai/media/craft_ai_logo_small.png'/>
            <p>03/12/2015</p>
            <aside class="notes" data-markdown>
              In this presentation, I'll introduce what we believe to be the
              main challenge for the next generation of IoT services and show
              how **craft ai** has been designed to help developers overcome it.
              Press space to move to the next slide.
            </aside>
          </section>
        </section>

        <section>
          <h1>There's a problem with IoT</h1>
          <em class="fragment">(well, there's one I'm gonna talk about)</em>
          <aside class="notes" data-markdown>
            The objective of IoT is to help people in their day-to-day life,
            however, we believe most of the proposed services are not so
            helpful...
          </aside>
        </section>

        <section>
          <section>
            <h1>Smart Objects services now...</h1>
          </section>

          <section>
            <h1>Dashboards</h1>
            <aside class="notes" data-markdown>
              The first big trend is: **dashboards** to see data
              coming from objects and send commands. Let's confuse end users
              with aircraft pilots and give them a bunch of graphs, metrics and
              actuators to play with.
            </aside>
          </section>

          <section>
            <img src='img/withings-dashboard.png'/>
            <aside class="notes" data-markdown>
              This example from [Withings](http://www.withings.com/) features
              sleeping patterns, percentages, numbers... how exciting!
            </aside>
          </section>

          <section>
            <img src='img/smartthings-dashboard.png'/>
            <aside class="notes" data-markdown>
              This is the result of a zealous users showing everything she can
              in the [SmartThings](http://www.smartthings.com/) dashboards. Pie
              charts, flags, bar graphs, science! I don't believe that this
              information is very useful or actionable for the user.
            </aside>
          </section>

          <section>
            <img src='img/zipato-dashboard.png'/>
            <aside class="notes" data-markdown>
              Just one more example, in a Smart Home context from
              [Zipato](http://zipato.com/). This time the user is not only given
              metrics, but also direct control over an array of actuators... which
              he has to manipulate one by one.
            </aside>
          </section>

          <section>
            <h1>Notifications</h1>
            <aside class="notes" data-markdown>
              In practice, users don't go to their dashboard to _pull_
              informations, hence this other strategy: _pushing_ notifications
              in real-time, as they occur.
            </aside>
          </section>

          <section>
            <img src='img/fitbit-notifications.png'/>
            <aside class="notes" data-markdown>
              Sometimes it's not so bad, you get qualified, hopefully
              interesting, information.
            </aside>
          </section>

          <section>
            <img src='img/smartthings-notifications.png'/>
            <aside class="notes" data-markdown>
              But this can get quickly out of hand, here 3 simultaneous
              notifications are sent, from a single SmartThings service.
              This is not unusual and is a consequence of the lack of reasoning
              on incoming events: in this case, _Baby Cakes_ and
              _rose@securitygem.com_ probably arrived together through the
              Garage.
            </aside>
          </section>

          <section>
            <img src='img/netatmo-notifications.jpg'/>
            <aside class="notes" data-markdown>
              Delivering only the raw event is rarely useful.
            </aside>
          </section>

          <section>
            <img src='img/smartthings-notifications2.png'/>
            <aside class="notes" data-markdown>
              The poor quality of these _smart_ notifications leads to only one
              outcome, they pile up...
            </aside>
          </section>

          <section>
            <h1>Are these the best we can do?</h1>
          </section>
        </section>

        <section>
          <section>
            <h1>Smart Services are...</h1>
            <aside class="notes" data-markdown>
              Hopefully, it's not impossible to find services that are actually smart.
            </aside>
          </section>

          <section>
            <img src='img/nest.jpg'/>
            <aside class="notes" data-markdown> The [Nest
              Thermostat](https://nest.com/thermostat/meet-nest-thermostat/) is
              one of our reference. It delivers a useful service by having a
              smart and simple UX and by seamlessly **learning** from the users
              inputs as well as reacting to its **context**, the presence of
              someone in the house.
            </aside>
          </section>

          <section>
            <img src='img/prizm.jpg'/>
            <aside class="notes" data-markdown>
              Another example of smart service around a connected device is
              [Prizm](http://www.meetprizm.com), a virtual DJ that'll chose the
              best music to play based what it perceives about the **context**
              and what it has **learnt** about the users tastes.
            </aside>
          </section>

          <section>
            <img class='no-bg' src='img/siri.png'/>
            <aside class="notes" data-markdown>
              Outside of IoT, several **virtual assistant** are emerging, they
              provide services that are perceived as _intelligent_ and are
              useful. [Apple Siri](http://www.apple.com/ios/siri/) is able to
              answer to queries in the **context** they're made, for example the
              currently playing movie, and based on information it has on the
              user.
            </aside>
          </section>

          <section>
            <img class='no-bg' src='img/google-now.png'/>
            <aside class="notes" data-markdown>
              [Google Now](https://www.google.com/landing/now/) relies on its
              user's **context** to proactively pushing her useful information.
            </aside>
          </section>

          <section>
            <img class='no-bg' src='img/facebook-m.png'/>
            <aside class="notes" data-markdown>
              [Facebook
              M](http://www.wired.com/2015/08/facebook-launches-m-new-kind-virtual-assistant/)
              is the latests addition to this family providing a full fledged
              concierge even relying on human to deliver smartness.
            </aside>
          </section>
        </section>

        <section>
          <section>
            <h2>Smart needs</h2>
            <h1 class="fragment">Awareness</h1>
            <h1 class="fragment">Learning</h1>
            <aside class="notes" data-markdown>
              Two aspects are common to these 5 examples of smart services:
                - **Awareness**, i.e. gathering and leveraging data from the usage _context_ through sensors or connection to existing services (messaging, social, ...);
                - **Learning**, i.e. progressively understand how each individual user interact with the service, its taste and preferences.
            </aside>
          </section>
          <section>
            <h1>AI!</h1>
            <img class='no-bg' src='img/glados.png'/>
            <aside class="notes" data-markdown>
              Of course, **AI** techniques can be used to enable this _awareness_ and _learning_.
            </aside>
          </section>
          <section>
            <h1>AI?</h1>
            <img src='img/data-scientist.jpg'/>
            <aside class="notes" data-markdown>
              I'm sure most of you associate AI to _Big Data_ & _Statistical
              Machine Learning_, maybe you're convinced you ned to hire a **Data
              Scientist** right now!
            </aside>
          </section>
          <section>
            <h1>But!</h1>
            <div class="fragment">
              <h2>AI is pretty hard to...</h2>
              <p>implement</p>
              <p>control</p>
              <p>explain</p>
            </div>
            <aside class="notes" data-markdown>
              The thing is, this kind of AI is not that straightforward.
              - Algorithms and data structures are pretty hard to implement,
              - Even if you use existing libraries or services, it's still very
              hard to control to achieve your business objectives,
              - Even if you have a data scientist in house, business experts
              still need to understand how this automated decision-making impact
              their service.
            </aside>
          </section>
          <section>
            <h1>Maybe, there's another way to do AI!</h1>
            <aside class="notes" data-markdown>
              We need to take a step back and think again. With our need for
              **awareness** and **learning**, we can find a better way to apply
              AI techniques.
            </aside>
          </section>
        </section>
        <section>
          <section data-background="img/flux-capacitor.jpg">
            <h1 class='light'>But first, some background</h1>
            <em class='light fragment'>(let's see how video games can help with our IoT problem)</em>
            <aside class="notes" data-markdown>
              To understand where we're coming form, let me give you a little
              bit of background on my experience working on **game AI**
              technologies for several years.
            </aside>
          </section>
          <section>
            <h1>Game AI</h2>
            <p>Autonomous characters</p>
            <p>Entertainment | Art | Pedagogy | Simulation</p>
            <aside class="notes" data-markdown>
              **Game AI** covers a variety of techniques designed to create
              autonomous characters in several industries: Video Games (duh),
              Movies, Training Simulation & Serious Games or any kind of
              simulations of systems where humans are involved.
            </aside>
          </section>
          <section>
            <img class="stamp" src='img/golaem.png'/>
            <video height="720px" autoplay loop muted>
              <source data-src="vid/golaem_alsitech.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
            <aside class="notes" data-markdown>
              This is a simulation project I've worked on at
              [Golaem](http://golaem.com) for the French railways company
              [SNCF](http://www.sncf.com).

              It involved **autonomous navigation** algorithms as well as the
              **modeling of passenger behaviors** from statistical and
              qualitative survey.
            </aside>
          </section>
          <section>
            <img class="stamp" src='img/golaem.png'/>
            <video height="720px" autoplay loop muted>
              <source data-src="vid/golaem_crowd.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
            <aside class="notes" data-markdown>
              Again at [Golaem](http://golaem.com), the same human behavior
              modeling stack is used by Golaem Crowd a product dedicated to the
              cinema industry.

              What's crucial is to enable to artists to **direct** the virtual
              extras to achieve their vision. AI is at the service of this
              vision.
            </aside>
          </section>

          <section>
            <img class="stamp" src='img/masa.png'/>
            <video height="720px" autoplay loop muted>
              <source data-src="vid/life.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
            <aside class="notes" data-markdown>
              Most of the **craft ai** team, including myself, worked at [MASA
              Group](http://masagroup.net) on LIFE, an AI middleware for Games &
              Simulation.

              Our main problematic was to enable designers to create
              **autonomous characters** that exhibit **the behavior they
              needed**. We achieved that using [**Behavior
              Trees**](http://www.craft.ai/blog/bt-101-behavior-trees-grammar-basics/)
              inside a carefully designed tool.
            </aside>
          </section>

          <section>
            <img class="stamp" src='img/masa.png'/>
            <video height="720px" autoplay loop muted>
              <source data-src="vid/life_adayinlife.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
            <aside class="notes" data-markdown>
              Use cases of LIFE include **games**, such as this ["The
              Sims"](https://www.thesims.com)-like games where characters
              interact with their environement autonomously based on their need
              and desires.

              For this kind of AI, **control** and **explainability** are
              crucial to balance the gameplay.
            </aside>
          </section>

          <section>
            <img class="stamp" src='img/masa.png'/>
            <video height="720px" autoplay loop muted>
              <source data-src="vid/life_military.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
            <aside class="notes" data-markdown>
              The main use case for LIFE is **military training simulation**.
              In this example, the character are created to follow a specific
              military doctrine.

              Reaching its pedagogical goals necessitates:
              - a **controled environment** to make the trainee work on specific
              skills,
              - an **autonomous environment** that can react properly to
              whatever the trainee decides to do.
            </aside>
          </section>
        </section>

        <section>
          <section>
            <h1>Lessons Learned</h2>
            <aside class="notes" data-markdown>
              I've worked for 6 years in this field and, on top of being able to
              show pretty videos, I learned some valuable lessons that are a core
              part of **craft ai** vision.
            </aside>
          </section>
          <section>
            <img src='img/illusion-of-life.jpg'/>
            <h3>Intelligent = credible as intelligent</h3>
            <p class="fragment">
              Perception | Usefulness | != Algorithm
            </p>
            <aside class="notes" data-markdown>
              Creating _"intelligent"_ interactions / experiences / services is
              about convincing the end-user its intelligent and by fulfilling
              her need.

              More importantly, you don't need fancy algorithms to make
              something intelligent.
            </aside>
          </section>
          <section>
            <img height=400 src='img/art-factory.jpg'/>
            <h3>AI = Content production</h3>
            <p class="fragment">
              Control | Predictability | Explainability
            </p>
            <aside class="notes" data-markdown>
              In fact, given unlimited time & resources, labor-intensive
              production of content, accounting for all possible cases would be
              ideal. **AI techniques enables the creation of such content within
              realistic constraints**.

              That's why these techniques need to allow the same **Quality
              Assurance** process any content creation would. Hence my emphasis
              on **control**, **predictability** and **explainability**.
            </aside>
          </section>
          <section>
            <img height=400 src='img/fair-team.jpg'/>
            <h3>Developers != AI experts</h3>
            <p class="fragment">
              Combinatorial complexity | Statefulness<br>Asynchronicity
            </p>
            <aside class="notes" data-markdown>
              The last takeaway, and in fact the drive behind the creation of AI
              authoring tools, is the realization that **most developers are not
              comfortable with decision-making AI techniques**.

              Furthermore, only some big companies have the resources to house
              teams of specialists.
            </aside>
          </section>
        </section>
        <section>
          <section>
            <img class="no-bg" src='http://www.craft.ai/media/craft_ai_square_logo.png' height='600px'/>
            <aside class="notes" data-markdown>
              **craft ai** is born from the realization that we can leverage
              what we learn in Game AI to enable every developers to create
              **aware** and **learning** services.
            </aside>
          </section>
          <section>
            <p>Enable developers to create AI that is<p>
            <p><strong>doing</strong> what they want</p>
            <p><strong>aware</strong> of their users' context</p>
            <p><strong>learning</strong> from their users</p>
            <h2 class="fragment">Directed Adaptable Agents</h2>
            <aside class="notes" data-markdown>
              The approach we built **craft ai** from values the control of the
              AI by the developer. This is key to make the solution efficient
              and easy to use. We focus our effort on enabling the creation of
              useful services for the end-user.

              We name this approach **directed adaptable agents**: the
              developers _direct agents_ that are able to _adapt their behavior_
              to the context and history.
            </aside>
          </section>
          <section>
            <img class="no-bg" src='img/workflow.png' />
            <aside class="notes" data-markdown>
              In practice, **craft ai** consists of two modules:
              - The [**workbench**](https://workbench.craft.ai) web app to
              define and inspect how the agents **behaviors**;
              - The cloud-based [**engine**](http://doc.craft.ai/integration/index.html)
              runs the behavors in **instances**, it is accessible with a
              REST API, it is used in two ways:
                1. Integrate **craft ai** with the developed application;
                2. Integrate **craft ai** with services and sensors through what
                we call **actions**.
            </aside>
          </section>
          <section>
            <!-- <div class="loading">
              <iframe src='https://workbench.craft.ai' allowtransparency width="1000" height="700" ></iframe>
            </div> -->
            <img class="no-bg" src='img/workbench.png' />
            <aside class="notes" data-markdown>
              This is **craft ai** browser-based workbench. It's basically an
              IDE for [Behavior Trees
              (BTs)](http://www.craft.ai/blog/bt-101-behavior-trees-grammar-basics/):
              the visual language **craft ai** uses to create AI by implementing
              the **behavior of agents**.

              This **explicit** grammar helps a lot with the
              combinatorial explosion thanks to its control flow nodes (in
              colors) and the asynchronicity and interruptibility of external
              calls thanks to its action formalism (reresented by **!**).

              For further information check our [user
              documentation](http://doc.craft.ai/behaviors/index.html).
            </aside>
          </section>
          <section>
            <img src='img/integrate.png'/>
            <aside class="notes" data-markdown>
              Once defined, BTs can be ran by **craft ai** cloud-based engine
              and controlled through its [**REST API**]((http://doc.craft.ai/integration/index.html).

              An app using **craft ai** will create, generally, an **instance**
              per end-user, each consisting of one or more **agents** executing
              BTs. During the instance lifetime each agent will store
              information about the end-user in its knowledge. This will be used
              to make more personalized decisions, to **learn** from the user.
            </aside>
          </section>
          <section>
            <!-- <div class="loading">
              <iframe src='http://www.craft.ai/ni' allowtransparency width="1000" height="700" ></iframe>
            </div> -->
            <img class="no-bg" src='img/ni.png' />
            <aside class="notes" data-markdown>
              As mentionned earlier, the Nest Thermostat is an very good example
              of a _smart_ IoT service. That's why we implemented one using
              **craft ai**.

              Thanks to our explicit agent-based approach, we've been able to
              combine the learning of the temperature planning, differencitate
              it explicitely between working and non-working day and add some
              heater monitoring.

              The demo is accessible and explained in more details
              [here](http://www.craft.ai/blog/NEST-like/).
            </aside>
          </section>
          <section>
            <h3>10 experts working on it since 03/2015</h3>
            <h3 class="fragment">Released on 10/2015</h3>
            <p class="fragment">
              <img class="logo" src='img/laposte.png'/>
              <img class="logo" src='img/sami.png'/>
              <img class="logo" src='img/gfi.png'/>
              <img class="logo" src='img/tieto.png'/>
              <img class="logo" src='img/axa.jpg'/>
              <img class="logo" src='img/lcl.png'/>
              <img class="logo" src='img/avidsen.png'/>
            </p>
            <aside class="notes" data-markdown>
              We're working on the product since March 2015 and have released a
              first version in October 2015. We're very lucky to already work with a
              range of early adopters in different industries. From personal
              assistants to enterprise processes, **craft ai** is not only for
              IoT.
            </aside>
          </section>
        </section>
        <section>
          <section data-background="img/hackathon.jpg">
            <h1>Hackathon IoT</h1>
            <h2>27- 29 Nov 2015</h2>
            <p class="fragment">
              <img class="logo" src='img/sncf.png'/>
              <img class="logo" src='img/loreal.png'/>
              <img class="logo" src='img/zagatub.png'/>
              <img class="logo" src='img/fonderie.png'/>
              <img class="logo" src='img/usine-digitale.png'/>
            </p>
            <aside class="notes" data-markdown>
              Before wrapping up, let's take a look at actual projects that were
              developped using **craft ai** during a Hackathon we sponsored in
              late November.

              10 teams worked for 2 days to create connected devices and their
              services. Further information on the hackathon can be found [here
              (in
              French)](http://www.usine-digitale.fr/article/revivez-le-premier-hackathon-des-objets-connectes-l-usine-digitale.N365840)
            </aside>
          </section>
          <section>
            <h1>AI?</h1>
            <p>Make sense of sensors</p>
            <p>Model physical systems</p>
            <p>Push relevant notifications</p>
            <p>Personalize assistants</p>
            <aside class="notes" data-markdown>
              Most project used, or planned to use, some AI to implement their
              service. The last two sections are perfect use cases for **craft
              ai**.
            </aside>
          </section>
          <section>
            <h1>SNCF Now</h1>
            <h4>Signal equipment issues with a push of a button</h4>
            <img height="400px" src='img/sncf-now.jpg'/>
            <aside class="notes" data-markdown>
              The **SNCF Now** team, winners of the mobility category, developed
              a physical button, that can be placed on existing equipment in
              trainstations, to let passenger report breakdowns and other issues.

              The project includes a maintenance platform, powered by **craft
              ai**, that routes alerts to the right technician in the station.
            </aside>
          </section>
          <section>
            <h1>Smart Mirror</h1>
            <h4>A beauty assistant in your bathroom</h4>
            <img height="400px" src='img/smart-mirror.jpg'/>
            <aside class="notes" data-markdown>
              The **Smart Mirror**, winner of the beauty & wellness category, is
              a bathroom mirror with a camera and screen that is able to provide
              personalized beauty advices based on scans from the camera, users
              habits and external information such as the events in her day.

              **craft ai** is used to implement this personal assistant leveraging
              these different data sources.
            </aside>
          </section>
          <section>
            <h1>Take Away</h1>
            <p class="fragment"><strong>Fun!</strong></p>
            <p class="fragment"><strong>Commit</strong></p>
            <p class="fragment">
              <strong>Manage Expectations</strong><br>
              <em>object-centric, no time for services</em><br>
              <em>marketer/developer ratio</em>
            </p>
            <aside class="notes" data-markdown>
              Being a tech partner for this hackathon was really fun, we sere
              able to explain **craft ai** and get feedback from a group of
              motivated users. This was also a big commitment, between the
              [workshop](http://www.craft.ai/blog/hackathon-usine-digitale/) we
              organized a week earlier and the presence during the week-end this
              was an important effort for the team.

              Finally, we had to manage our expectations, most of the teams were
              interested by what **craft ai** allowed them to do but most didn't
              had the time to actually play with it. The hackathon was very
              object-centric and there was only a few developers.
            </aside>
          </section>
        </section>
        <section>
          <section>
            <h3>Good IoT services are <strong>Aware & Learn</strong></h3>
            <h3>Usable tools are <strong>Whiteboxes</strong><h3>
            <aside class="notes" data-markdown>
              As a wrap-up for this presentation, I'd like to reemphasize my
              main messages:
              - Awareness and learning are key to the creation of good services,
              especially in the IoT field,
              - The concept of **whitebox** can really help making AI accessible
              to every developers.
            </aside>
          </section>
          <section>
            <img class="no-bg" src='http://www.craft.ai/media/craft_ai_bouncing_stanley.gif'/>
            <h1><a href="https://workbench.craft.ai">Sign up now!</a></h1>
            <p>
              <a href="https://twitter.com/clodericmars">@clodericmars</a> | <a href="https://twitter.com/craft_ai">@craft_ai</a>
            </p>
            <aside class="notes" data-markdown>
              **craft ai** is already available to help you with that, sign up
              now at [workbench.craft.ai](https://workbench.craft.ai)!
            </aside>
          </section>
          <section>
            <p>
              <a href="https://github.com/craft-ai/paris-ai-robotics-and-iot-meetup-2">View sources on github...</a>
            </p>
            <img class="no-bg"  src="https://i.creativecommons.org/l/by-nc/4.0/88x31.png" alt="Licence Creative Commons"/>
            <p>
              The content of this presentation is published under the <a href="http://creativecommons.org/licenses/by-nc/4.0/">Attribution-NonCommercial 4.0 International</a>
            </p>
          </section>
      </section>
      </div>
    </div>

    <script src="lib/js/head.min.js"></script>
    <script src="js/reveal.js"></script>

    <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        controls: true,
        progress: true,
        history: true,
        center: true,
        showNotes: true,
        fragments: false,

        transition: 'slide', // none/fade/slide/convex/concave/zoom

        // Optional reveal.js plugins
        dependencies: [
          { src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
          { src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
          { src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
          { src: 'plugin/notes/notes.js', async: true }
        ]
      });

    </script>

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-62170585-1', 'auto');
      ga('send', 'pageview');

    </script>

  </body>
</html>
